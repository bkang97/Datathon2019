# R, Python and Mathematica Codes in Data Science

<b> Welcome to my GitHub repo. </b>

I am a Data Scientist and I code in R, Python and Wolfram Mathematica. Here you will find some Machine Learning, Deep Learning, Natural Language Processing and Artificial Intelligence models I developed.

<b> Outputs of the models can be seen at my portfolio: </b> https://drive.google.com/file/d/0B0RLknmL54khdjRQWVBKeTVxSHM/view?usp=sharing

------------------
# Mathematica Codes

<b> MNIST_HOT.5.FULL:  </b>	is a solution for the MNIST dataset in Mathematica, with 96.51% accuracy, based on difference of pixels.

<b> Mathematica - Artificial Intelligence Simulating Interactions in Social Networks:  </b>	is a model that simulates human interactions in a social network using cellular automata and agent-based modeling. Each agent has 3 possible choices for interation and a memory. The code has 14 pages with a big loop included in one line of code.

<b> Mathematica - Facial Recognition in Movement: </b> This code operationalizes facial recognition in a downloaded YouTube video. The output is also a video with the result of face recognition (YouTube link of the output is included in code page)

<b> Mathematica - Monte Carlo Simulation: </b> is an animated model of a Markov Chain Monte Carlo Simulation for autonomous driving. A video of the dynamic output was also generated and link for the YouTube video is included in code page.
  
<b> Mathematica - Social Network Surveillance:  </b>	is a model that tracks individuals in a social network, tracks also his connections and future interactions.

<p align="center">
<img src=https://github.com/RubensZimbres/Repo-2016/blob/master/pictures/MNIST_FINAL.jpg?raw=true>
</p>

------------------
# Python Codes

Keras version used in models: keras==1.1.0 | LSTM 0.2

<b> Python - Autoencoder MNIST:  </b>	is an autoencoder model for classification of images developed with Keras, for the MNIST dataset, with model Checkpoint as a callback to save weights.

<b> Python - Autoencoder for Text Classification:  </b>	is an autoencoder model for classification of text made with Keras, also with model Checkpoint.

<b> Python - Deep Learning with Lasagne:  </b>	is a deep neural network developed with Lasagne, where you can see values of weights in each layer, including bias.

<b> Python - Face Recognition: </b>	is a model using OpenCV to detect faces.

<b> Python - Image Extraction from Twitter: </b>	is a model that extracts pictures and their links from Twitter webpages, plotting with matplotlib.

<b> Python - Keras Convolutional Neural Network: </b> is a CNN developed to classify the MNIST dataset with an accuracy greater than 99%.

<b> Python - Keras Deep Regressor: </b>	is a deep Neural Network for prediction of a continuous output made with Keras, learning rate scheduler according to derivative of error, random initial weights, with loss history.

<b> Python - Keras LSTM Network: </b>	is a Recurrent Neural Network (LSTM) to predict and generate text.

<b> Python - Keras Multi Layer Perceptron: </b>	is a MLP model, Neural Networks made with Keras with loss history, scheduled learning rate according to derivative of error for prediction and classification.

<b> Python - Machine Learning: </b> is a Principal Components Analysis followed by a Linear Regression.

<b> Python - NLP Doc2Vec: </b>	is a Natural Language Processing model where I asked a Wikipedia webpage a question and 4 possible answers were semantically chosen from the tokenized and vectorized webpage, using KNN and cosine distance.

<b> Python - NLP Semantic Analysis: </b>	is a Natural Language Processing model that classifies a given sentence according to semantic similarity to other sentences, using cosine distance.

<b> Python - NLP Word2Vec: </b>	is a model developed from scratch to measure cosine similarity among words.

<b> Python - Reinforcement Learning: </b>	is a model based on simple rules and Game Theory where agents attitude change according to payoff achieved. Can be adapted for tit-for-tat strategy, always cooperate, always defeat and other strategies. Rewards were placed in the payoff matrix.

<b> Python - Social Networks: </b>	is a model that draws social networks configuration and connections.

<b> Python - Support Vector Machines: </b>	is a Machine Learning model that classifies the Iris dataset with SVM and plots it.

<b> Python - Theano Deep Learning: </b>	is a Neural Network with two hidden layers using Theano.

<p align="center">
<img src=https://github.com/RubensZimbres/Repo-2016/blob/master/pictures/GENSIM_Word2Vec.jpg?raw=true>
</p>

------------------
# R Codes

<b> R - Churn of Customers: </b> is a model that uses a logistic regression associated with a threshold to predict which customers present the greater risk to be lost.

<b> R - Data Cleaning + Multinomial Regression: </b>	is a model that presents data cleaning and a multinomial regression using package nnet to classify customers according to their level of loyalty.

<b> R - Face Recognition: </b>	is a code to detect faces and objects in R.

<b> R - Geolocation Brazil: </b>	is a file for geo-spatial localization, brazilian map.

<b> R - Geolocation USA: </b>	is also a file for geo-spatial localization, USA map.

<b> R - Geolocation World: </b>	is a file for geo-spatial localization, world map, zoom available, customizable icons.

<b> R - Gradient Descent Logistic: </b>	is a model that performs a gradient descent to define a threshold for the sigmoid function in a Logistic Regression. Boosting was implemented and ROC curves compared.

<b> R - H2O Deep Learning: </b>	is a Neural Network model developed to predict recommendations and word-of-mouth advertising.

<b> R - Imbalanced classes </b> is a model for employee churn, where features have no correlation with target variable and also there are imbalanced classes in the proportion 1/20. A logistic regression from scratch is applied, a hill climbing gradient is used to define the best threshold for the logistic function and after that, boosting was compared regarding AUC in a ROC plot.

<b> Logistic Regression + Gradient Descent + Boosting </b> is a model where features have no correlation with target variable. Logistic Regression with Gradient Descent was applied, and then Boosting.

<b> R - MNIST: </b>	is a solution for the MNIST dataset, developed from scratch.

<b> R - Markov Chains: </b>	is a simple visualization of Markov Chains and probabilities associated.

<b> R - NeuralNet: </b> is a Neural Network model developed to predict and classify word-of-mouth advertising.

<b> R - Ridge Regression: </b> is a model with Ridge Regularization made from scratch to prevent overfitting.

<b> R - Deep Learning: </b> is a Neural Network model with 2 hidden layers for prediction of a continuous variable.

<p align="center">
<img src=https://github.com/RubensZimbres/Repo-2016/blob/master/pictures/StockMarket.DOW.JONES.png?raw=true>
</p>

<p align="center">
<img src=https://github.com/RubensZimbres/Repo-2016/blob/master/pictures/Geolocation.png?raw=true>
</p>
